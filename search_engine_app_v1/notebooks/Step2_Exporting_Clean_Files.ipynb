{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "528cb7f3-35d8-4446-a7f8-16a52114fe65",
   "metadata": {},
   "source": [
    "# Taking Each File From Subtitle Folder, Cleaning It & Saving It To Another Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2eebc463-102c-4d6d-9803-41ebfceb925b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "import re\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e021173-f5f3-4b1c-bc8f-988b1a415582",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\adykh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5914676e-ce2f-4224-af70-e3b3bc8ef2c0",
   "metadata": {},
   "source": [
    "# Function Will Take Each Subtitle File From Specified Folder, Clean It, & Return Clean File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae839726-1a66-4e0e-9851-e74b0cdbd99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string \n",
    "\n",
    "def clean_subtitle_file(subtitle_text):\n",
    "    # Check if the subtitle text follows the first format\n",
    "    if 'Dialogue:' in subtitle_text:\n",
    "        return clean_first_format(subtitle_text)\n",
    "    # Check if the subtitle text follows the second format\n",
    "    elif re.search(r'\\d{2}:\\d{2}:\\d{2},\\d{3} --> \\d{2}:\\d{2}:\\d{2},\\d{3}\\n?', subtitle_text):\n",
    "        return clean_second_format(subtitle_text)\n",
    "    else:\n",
    "        # If the format is not recognized, return the original text\n",
    "        return subtitle_text\n",
    "#####################################################################################################\n",
    "def clean_first_format(subtitle_text):\n",
    "    # Split the subtitle text into lines\n",
    "    lines = subtitle_text.split('\\n')\n",
    "    # Initialize an empty list to store cleaned lines\n",
    "    cleaned_lines = []\n",
    "    # Iterate through each line\n",
    "    for line in lines:\n",
    "        # Find the index of the first occurrence of 'Dialogue: '\n",
    "        start_index = line.find('Dialogue: ')\n",
    "        if start_index != -1:\n",
    "            # Find the index of the closing curly brace '}'\n",
    "            end_index = line.find('}', start_index)\n",
    "            if end_index != -1:\n",
    "                # Keep the part of the line after '}'\n",
    "                cleaned_line = line[end_index + 1:].replace('\\\\N', ' ').strip()\n",
    "                # Remove text within curly braces and the braces themselves\n",
    "                cleaned_line = re.sub(r'\\{.*?\\}', '', cleaned_line)\n",
    "                # Remove numbers at the beginning of the line\n",
    "                cleaned_line = re.sub(r'^\\d+\\s*', '', cleaned_line)\n",
    "                # Remove special characters and punctuation\n",
    "                cleaned_line = re.sub(r'[^\\w\\s]', '', cleaned_line)\n",
    "                # Convert text to lowercase\n",
    "                cleaned_line = cleaned_line.lower()\n",
    "                # Tokenize the text\n",
    "                words = word_tokenize(cleaned_line)\n",
    "                # Remove stop words\n",
    "                stop_words = set(stopwords.words('english'))\n",
    "                words = [word for word in words if word not in stop_words]\n",
    "                # Join the words back into a single string\n",
    "                cleaned_line = ' '.join(words)\n",
    "                cleaned_lines.append(cleaned_line)\n",
    "    # Join the cleaned lines into a single string\n",
    "    cleaned_text = ' '.join(cleaned_lines)\n",
    "\n",
    "    return cleaned_text\n",
    "#######################################################################################################\n",
    "def clean_second_format(subtitle_text):\n",
    "    # Remove UTF-8 Byte Order Mark (BOM)\n",
    "    cleaned_text = subtitle_text.strip('\\ufeff')\n",
    "    # Regular expression to match timestamps\n",
    "    timestamp_regex = r'\\d{2}:\\d{2}:\\d{2},\\d{3} --> \\d{2}:\\d{2}:\\d{2},\\d{3}'    \n",
    "    # Remove timestamps\n",
    "    cleaned_text = re.sub(timestamp_regex, '', subtitle_text)    \n",
    "    # Remove numbers\n",
    "    cleaned_text = re.sub(r'\\d+', '', cleaned_text)    \n",
    "    # Remove punctuation\n",
    "    cleaned_text = cleaned_text.translate(str.maketrans('', '', string.punctuation))    \n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(cleaned_text)    \n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [word for word in tokens if word.lower() not in stop_words]    \n",
    "    # Join the tokens back into a string\n",
    "    cleaned_text = ' '.join(filtered_tokens)    \n",
    "    # Remove any leading or trailing whitespace\n",
    "    cleaned_text = cleaned_text.strip()    \n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db0c045-3a63-4f3a-8028-92cb6f82a37a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8c8bce-d48e-4876-bc0c-6a6482ed2f6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92808496-287b-4699-823b-4917ed46deac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b969fc3-9b4d-4b4f-b837-0bae9907adcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb03502-518a-4b52-aadd-62bfdf34389c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ec3d78a-2929-41e9-9542-31b3f3383b73",
   "metadata": {},
   "source": [
    "# METADATA Extracting Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aceab394-44ab-4c2d-bc66-ef411459ac4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_metadata(text):\n",
    "    # Initialize default values for metadata fields\n",
    "    show_name = \"Unknown\"\n",
    "    show_title = \"Unknown\"\n",
    "    year = \"Unknown\"\n",
    "    season = \"Unknown\"\n",
    "    episode = \"Unknown\"\n",
    "    subtitle_language = \"Unknown\"\n",
    "\n",
    "    # Define regular expression patterns for extracting metadata\n",
    "    pattern1 = re.compile(r\"^(.*?)\\.s(\\d{2})\\.e(\\d{2})\\.(.*?)\\((\\d{4})\\)\\.(.*?)\\.txt$\")\n",
    "    pattern2 = re.compile(r\"^(.*?)\\((\\d{4})\\)\\.(.*?)\\.(\\d+)cd\\.txt$\")\n",
    "    pattern3 = re.compile(r\"^\\(?([^)]*)\\)?\\.(\\w+)\\.(\\d+)cd\\.txt$\")\n",
    "    pattern4 = re.compile(r\"^(.*?)\\.txt$\")\n",
    "\n",
    "    match = pattern1.match(text)\n",
    "    if match:\n",
    "        show_name = match.group(1).strip() if match.group(1) else \"Unknown\"\n",
    "        show_title = match.group(4).strip() if match.group(4) else \"Unknown\"\n",
    "        season = match.group(2) if match.group(2) else \"Unknown\"\n",
    "        episode = match.group(3) if match.group(3) else \"Unknown\"\n",
    "        year = match.group(5)\n",
    "        subtitle_language = match.group(6).split(\".\")[0] if match.group(6) else \"Unknown\"\n",
    "    else:\n",
    "        match = pattern2.match(text)\n",
    "        if match:\n",
    "            show_name = match.group(1).strip() if match.group(1) else \"Unknown\"\n",
    "            subtitle_language = match.group(3).split(\".\")[0] if match.group(3) else \"Unknown\"\n",
    "            year = match.group(2)\n",
    "        else:\n",
    "            match = pattern3.match(text)\n",
    "            if match:\n",
    "                show_name = match.group(1).strip() if match.group(1) else \"Unknown\"\n",
    "                show_title = \"Unknown\"\n",
    "                season = \"Unknown\"  # Set season to \"Unknown\"\n",
    "                year = \"Unknown\"  # Set year to \"Unknown\"\n",
    "                subtitle_language = match.group(2) if match.group(2) else \"Unknown\"\n",
    "            else:\n",
    "                match = pattern4.match(text)\n",
    "                if match:\n",
    "                    show_name = match.group(1).strip() if match.group(1) else \"Unknown\"\n",
    "                    year = \"Unknown\"  # Year is unknown for this pattern\n",
    "                    subtitle_language = \"Unknown\"  # Language is unknown for this pattern\n",
    "                else:\n",
    "                    print(f\"Could not extract metadata from '{text}'\")\n",
    "\n",
    "    return {\n",
    "        'show_name': show_name,\n",
    "        'show_title': show_title,\n",
    "        'year': year,\n",
    "        'season': season,\n",
    "        'episode': episode,\n",
    "        'subtitle_language': subtitle_language\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655d62cb-e846-42b9-a903-37f9cd75462f",
   "metadata": {},
   "source": [
    "# Function To Return DataFrame\n",
    "\n",
    "**Function Will Create Folder To Store Cleaned Subtitles Files, Also, In Order To Store Records Of Each File, A DataFrame Will Be Created Which Will Store METADATA Of Each Subtitle File, Along With, Unique ID For Each file Along With Its Name.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4a0d913-d868-44dc-aee7-e3754395b03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_subtitle_folder(input_folder, output_folder):\n",
    "    # Create output folder if not present\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Initialize list to store data\n",
    "    data = []\n",
    "\n",
    "    # Iterate through each file in the input folder\n",
    "    for file_name in os.listdir(input_folder):\n",
    "        if file_name.endswith('.txt'):\n",
    "            file_path = os.path.join(input_folder, file_name)\n",
    "            # Read the content of the subtitle file\n",
    "            with open(file_path, 'r', encoding='utf-8-sig') as file:\n",
    "                subtitle_text = file.read()\n",
    "\n",
    "            # Clean the subtitle file content\n",
    "            cleaned_text = clean_subtitle_file(subtitle_text)\n",
    "            \n",
    "            # Save cleaned text to output folder with the same filename\n",
    "            clean_file_path = os.path.join(output_folder, file_name)\n",
    "            with open(clean_file_path, 'w', encoding='utf-8-sig') as file:\n",
    "                file.write(cleaned_text)\n",
    "            \n",
    "            # Extract metadata\n",
    "            metadata = extract_metadata(file_name)\n",
    "            \n",
    "            # Create entry for DataFrame\n",
    "            entry = {\n",
    "                'id': len(data),\n",
    "                'metadata': metadata,\n",
    "                'file_name': file_name\n",
    "            }\n",
    "            \n",
    "            # Append entry to data list\n",
    "            data.append(entry)\n",
    "    \n",
    "    # Create DataFrame from collected data\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9634f0c-50b3-4fc7-b3cd-1c052e5641ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "input_folder = r\"C:\\Users\\adykh\\Desktop\\subs_db\\subtitles\\subtitle_30\\subtitles_data_30%\"\n",
    "output_folder = r\"C:\\Users\\adykh\\Desktop\\subs_db\\subtitles\\subtitle_30\\cleaned_subtitles_data_30%\"\n",
    "df = clean_subtitle_folder(input_folder, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45602b3c-a4d2-4ba6-b873-8a944cf7bf01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6ca248-4a9b-4cc4-b5c5-4728699ea3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Export DataFrame to CSV\n",
    "df.to_csv('subtitles_data_30%.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45d7f6e-c7c5-4902-b710-1aa6657120c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['metadata'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9174dac4-4c31-48f4-bcd0-5f6c14e90fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['metadata'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbba4015-1296-46f8-85d5-5cf59c60bb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['metadata'][21]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec4f082-7f37-4676-88ab-4da149a6478c",
   "metadata": {},
   "source": [
    "=============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd8840e-45eb-4f6f-bb73-b52760f23d35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f033ad2-34ba-4d24-bd7c-2cb071343a20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1267ee26-d3b0-4d33-9b12-3e27f56d3e77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7710b5b-67c3-470c-9980-f846186adeaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b6f072-6382-4efe-a8d3-dad1dc6c3c1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a472dd8b-f74c-4899-b786-89b0f5688a65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dacd641-9a64-4211-93d9-c69bc22f8967",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6485ee6c-c6d8-4a58-b96b-b1de64d1e7c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa253c3-d394-44c5-8f19-4fe2056bf356",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e586264a-2424-4069-83e7-aa37618927c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d4a739-5b97-4908-aef2-c912991892e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512f52db-bd0d-4214-8fd4-30559c26d97e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37029ed-4875-4a3b-a51f-4a81333800a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f885ef3-d486-4d19-bf23-f324138da228",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fa30d8-8cd6-4289-bede-dda8e42abf86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e09c7d2-82d9-465a-a513-716d6ea6a3be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec5d472-c5be-4f1b-ac14-b374cc2f382d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9673e87e-7183-4886-a348-86a7d32fc64b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
